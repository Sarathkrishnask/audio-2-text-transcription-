Audio to Text Transcript with Speaker Diarization ğŸ™ï¸ğŸ“
This project processes long audio files (e.g. `.mp3`) into clean, speaker-separated transcripts using a combination of audio enhancement, speaker diarization, and transcription via OpenAI's Whisper model.
ğŸ” Features
â€¢	ğŸ§ Converts `.mp3` audio to `.wav` format
â€¢	âœ‚ï¸ Splits audio into smaller, manageable chunks
â€¢	ğŸ”Š Enhances audio quality
â€¢	ğŸ§  Transcribes using OpenAI's Whisper (medium model)
â€¢	ğŸ—£ï¸ Identifies individual speakers (speaker diarization)
â€¢	ğŸ•’ Outputs timestamps with who spoke what
â€¢	ğŸ“„ Saves results as readable documents (e.g. `.txt`, `.docx`)
ğŸš€ Try It in Google Colab
You can run the whole pipeline in Colab with zero setup. Just upload your audio file and follow the cells.
Notebook	Description	Open in Colab
ğŸ”Š Main Transcription Pipeline	Full audio to speaker transcript	https://colab.research.google.com/drive/1-LiE4CSCVA6RGOCvQkMK_TL9SvkyG7gW#scrollTo=yuXIr36FCoEW
ğŸ¯ Alternate Transcriber	Alternative transcription pipeline	https://colab.research.google.com/drive/1u5aL_21tkqKm-WoUnu9ZblQ0EWFfQdtq
ğŸ“¹ Zoom Meeting Transcriber	Extracts speaker transcript from Zoom recordings	https://colab.research.google.com/drive/1zEHYisMz_PK-gevJGtifmYD_StMe3iRT
ğŸ§± Libraries & Tools Used
â€¢	whisper (OpenAI transcription)
â€¢	pydub, soundfile (audio handling)
â€¢	pyannote.audio, simple_diarizer (speaker diarization)
â€¢	matplotlib (visualizations)
â€¢	torch, numpy, pandas
ğŸ“¦ How to Use
1.	Open any Colab link above.
2.	Upload your `.mp3` audio file to Colab.
3.	Provide the file path in the notebook input cell.
4.	Run all cells (Shift + Enter).
5.	Receive:
 - A plotted waveform with speaker labels.
 - A text-based transcript with timestamps.
ğŸ“¸ Sample Output
 
 
ğŸ“ Transcript Sample
[00:00:00] Speaker 1: Hi Lucy, nice to meet you. So I understand that you were referred here by your GP...
[00:00:10] Speaker 0: Yes, that's right. I've been feeling quite down lately...
âœï¸ Author
Built by SARATHKUMAR R
